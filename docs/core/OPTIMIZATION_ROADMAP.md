# ä¼˜åŒ–è·¯çº¿å›¾ (Optimization Roadmap)

> **æ–‡æ¡£ç±»å‹:** å¼€å‘è®¡åˆ’ / æŠ€æœ¯å€ºè·Ÿè¸ª
> **ç›®æ ‡:** è®°å½• Job Intelligence é¡¹ç›®çš„å¾…ä¼˜åŒ–é¡¹ï¼ŒæŒ‰ä¼˜å…ˆçº§ç»„ç»‡ï¼Œä¾¿äºåç»­è¯„ä¼°å’Œå®æ–½
> **æœ€åæ›´æ–°:** 2025-12-20

---

## ğŸ“‹ æ–‡æ¡£è¯´æ˜

æœ¬æ–‡æ¡£è®°å½• **Python çˆ¬è™«æœåŠ¡ï¼ˆscrape-api/ï¼‰** å’Œ **.NET åç«¯æœåŠ¡** çš„ä¼˜åŒ–ä»»åŠ¡ã€‚

**ä½¿ç”¨æ–¹å¼:**
- âœ… æ ¸å¿ƒåŠŸèƒ½å®Œæˆåï¼Œå›é¡¾æ­¤æ–‡æ¡£è¯„ä¼°æ˜¯å¦éœ€è¦ä¼˜åŒ–
- âœ… é¢è¯•å‡†å¤‡æ—¶ï¼Œå‚è€ƒæ­¤æ–‡æ¡£è®²è¿°é¡¹ç›®çš„æ”¹è¿›ç©ºé—´
- âœ… å­¦ä¹ æ–°æŠ€æœ¯æ—¶ï¼Œä» P2-P3 ä»»åŠ¡ä¸­é€‰æ‹©å®è·µé¡¹ç›®

**ä¼˜å…ˆçº§å®šä¹‰:**
- **P1 (Important):** å½±å“ç³»ç»Ÿç¨³å®šæ€§å’Œå¯ç»´æŠ¤æ€§ï¼Œå»ºè®®å°½å¿«å®Œæˆ
- **P2 (Nice-to-Have):** æå‡æ€§èƒ½å’Œç”¨æˆ·ä½“éªŒï¼Œå¯æ ¹æ®éœ€æ±‚è¯„ä¼°
- **P3 (Future):** åŠŸèƒ½æ‰©å±•ï¼Œå¯å»¶ååˆ° V2 ç‰ˆæœ¬

---

## ğŸ¯ å½“å‰çŠ¶æ€æ€»è§ˆ

### Python çˆ¬è™«æœåŠ¡

| ç±»åˆ« | P1 | P2 | P3 |
|------|----|----|-----|
| æµ‹è¯• | 2/2 âœ… | 0/0 | 0/0 |
| é”™è¯¯å¤„ç† | 2/2 âœ… | 0/1 | 0/0 |
| æ€§èƒ½ä¼˜åŒ– | 0/0 | 0/3 | 0/0 |
| æ—¥å¿—ç›‘æ§ | 0/0 | 0/2 | 0/0 |
| åŠŸèƒ½æ‰©å±• | 0/0 | 0/0 | 0/3 |

**æ€»è®¡:** 4/11 ä»»åŠ¡å®Œæˆï¼ˆ36.4%ï¼‰
**P1 ä»»åŠ¡å®Œæˆç‡:** 100% (4/4) ğŸ‰
**æœ€åæ›´æ–°:** 2025-12-21

### .NET åç«¯æœåŠ¡

| ç±»åˆ« | P1 | P2 | P3 |
|------|----|----|-----|
| é›†æˆæµ‹è¯• | 0/1 | 0/0 | 0/0 |
| æ€§èƒ½ä¼˜åŒ– | 0/0 | 0/2 | 0/0 |
| åŠŸèƒ½æ‰©å±• | 0/0 | 0/0 | 0/2 |

**æ€»è®¡:** 0/5 ä»»åŠ¡å®Œæˆï¼ˆ0%ï¼‰

---

## ğŸ”§ Python çˆ¬è™«æœåŠ¡ä¼˜åŒ–ä»»åŠ¡

### P1 - è´¨é‡ä¿è¯ (Important)

#### 1.1 SeekAdapter å•å…ƒæµ‹è¯• âœ…

**çŠ¶æ€:** å·²å®Œæˆ
**å®é™…æ—¶é—´:** 1.5 å°æ—¶
**å®Œæˆæ—¶é—´:** 2025-12-21

**ä»»åŠ¡æè¿°:**
- å½“å‰ SeekAdapter åªæœ‰æ‰‹åŠ¨æµ‹è¯•å’Œç«¯åˆ°ç«¯æµ‹è¯•
- ç¼ºå°‘å•å…ƒæµ‹è¯•è¦†ç›–æ ¸å¿ƒæ–¹æ³•

**å·²å®Œæˆä»»åŠ¡:**
```python
# tests/test_seek_adapter.py (23 ä¸ªæ–°æµ‹è¯•)
âœ… test_build_params_basic()                    # URL å‚æ•°æ„å»º
âœ… test_build_params_max_results()              # æœ€å¤§ç»“æœæ•°
âœ… test_build_params_keywords_with_spaces()     # å¸¦ç©ºæ ¼å…³é”®è¯
âœ… test_extract_description_from_teaser()       # ä» teaser æå–
âœ… test_extract_description_from_bullet_points() # ä» bulletPoints æå–
âœ… test_extract_description_truncate_*()        # é•¿æè¿°æˆªæ–­ï¼ˆ2ä¸ªï¼‰
âœ… test_extract_description_empty*()            # ç©ºæè¿°å¤„ç†ï¼ˆ2ä¸ªï¼‰
âœ… test_transform_job_success()                 # æ­£å¸¸æ•°æ®è½¬æ¢
âœ… test_transform_job_missing_*()               # ç¼ºå°‘å­—æ®µï¼ˆ2ä¸ªï¼‰
âœ… test_transform_job_no_*()                    # å¯é€‰å­—æ®µç¼ºå¤±ï¼ˆ3ä¸ªï¼‰
âœ… test_transform_job_invalid_*()               # æ— æ•ˆæ•°æ®ï¼ˆ2ä¸ªï¼‰
âœ… test_transform_job_*_company_field()         # å¤‡é€‰å­—æ®µï¼ˆ2ä¸ªï¼‰
âœ… test_scrape_success()                        # æˆåŠŸæŠ“å–ï¼ˆmockï¼‰
âœ… test_scrape_empty_results()                  # ç©ºç»“æœ
âœ… test_scrape_partial_failures()               # éƒ¨åˆ†å¤±è´¥
âœ… test_scrape_max_results_adjustment()         # å‚æ•°è°ƒæ•´
```

**æˆåŠŸæ ‡å‡†:**
- âœ… æ–°å¢ 23 ä¸ªå•å…ƒæµ‹è¯•ï¼ˆè¶…å‡ºé¢„æœŸï¼‰
- âœ… è¦†ç›–æ ¸å¿ƒæ•°æ®è½¬æ¢é€»è¾‘
- âœ… æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼ˆ92/92 = 100%ï¼‰

**å‘ç°çš„é—®é¢˜å’Œä¿®å¤:**
- âœ… **Bug ä¿®å¤:** SeekAdapter ä¸­ `parse_location()` è¿”å›å€¼èµ‹å€¼é”™è¯¯
  - åŸä»£ç ï¼š`city, state = parse_location(location_label)`
  - ä¿®å¤åï¼š`state, suburb = parse_location(location_label)`
  - å½±å“ï¼šDTO ä¸­ `location_suburb` å’Œ `location_state` å­—æ®µå€¼äº’æ¢

**æµ‹è¯•è¦†ç›–æå‡:**
- æ€»æµ‹è¯•æ•°ï¼š69 â†’ 92 (+23)
- æ‰§è¡Œæ—¶é—´ï¼š0.30 ç§’
- é€šè¿‡ç‡ï¼š100%

**æ”¶ç›Š:**
- âœ… æå‰å‘ç°äº†æ•°æ®å­—æ®µèµ‹å€¼é”™è¯¯çš„ bug
- âœ… è¦†ç›–äº†æ‰€æœ‰è¾¹ç¼˜æƒ…å†µï¼ˆç¼ºå°‘å­—æ®µã€æ— æ•ˆæ•°æ®ã€å¤‡é€‰å­—æ®µï¼‰
- âœ… ä¸ºæœªæ¥é‡æ„æä¾›äº†å®‰å…¨ç½‘
- âœ… é¢è¯•æ—¶å¯ä»¥å±•ç¤ºå®Œæ•´çš„ TDD æµç¨‹

---

#### 1.2 é”™è¯¯å¤„ç†ç»†åŒ– âœ…

**çŠ¶æ€:** å·²å®Œæˆ
**å®é™…æ—¶é—´:** 1 å°æ—¶
**å®Œæˆæ—¶é—´:** 2025-12-21

**ä»»åŠ¡æè¿°:**
- å½“å‰æ‰€æœ‰å¼‚å¸¸éƒ½æ•è·ä¸ºé€šç”¨ Exception
- æ— æ³•åŒºåˆ†ç½‘ç»œé”™è¯¯ã€æ•°æ®æ ¼å¼é”™è¯¯ã€ä¸šåŠ¡é€»è¾‘é”™è¯¯

**å·²å®Œæˆä»»åŠ¡:**
```python
# app/exceptions.py - åˆ›å»ºå®Œæ•´çš„å¼‚å¸¸ä½“ç³»ï¼ˆ280 è¡Œï¼‰
âœ… ScraperException                    # åŸºç¡€å¼‚å¸¸ç±»
âœ… ScraperNetworkError                 # ç½‘ç»œé”™è¯¯
âœ… ScraperTimeoutError                 # è¶…æ—¶é”™è¯¯ï¼ˆç»§æ‰¿è‡ª NetworkErrorï¼‰
âœ… RateLimitException                  # é€Ÿç‡é™åˆ¶ï¼ˆç»§æ‰¿è‡ª NetworkErrorï¼‰
âœ… ScraperDataError                    # æ•°æ®æ ¼å¼é”™è¯¯
âœ… ScraperValidationError              # éªŒè¯é”™è¯¯
âœ… ScraperParsingError                 # è§£æé”™è¯¯ï¼ˆç»§æ‰¿è‡ª DataErrorï¼‰
âœ… PlatformException                   # å¹³å° API é”™è¯¯
âœ… ScraperAuthenticationError          # è®¤è¯é”™è¯¯ï¼ˆç»§æ‰¿è‡ª PlatformExceptionï¼‰
âœ… ScraperNotFoundError                # èµ„æºä¸å­˜åœ¨ï¼ˆç»§æ‰¿è‡ª PlatformExceptionï¼‰
âœ… ScraperConfigurationError           # é…ç½®é”™è¯¯
âœ… classify_http_error()               # HTTP çŠ¶æ€ç åˆ†ç±»å‡½æ•°

# app/adapters/seek_adapter.py - æ›´æ–°é”™è¯¯å¤„ç†
âœ… _call_seek_api() æ–¹æ³•ï¼š
  - requests.Timeout â†’ ScraperTimeoutError
  - requests.HTTPError â†’ classify_http_error()
  - requests.ConnectionError â†’ ScraperNetworkError
  - JSON è§£æå¤±è´¥ â†’ ScraperDataError
  - å“åº”æ ¼å¼é”™è¯¯ â†’ ScraperDataError

âœ… _transform_job() æ–¹æ³•ï¼š
  - ç¼ºå°‘å¿…éœ€å­—æ®µ â†’ ScraperValidationErrorï¼ˆå¸¦å­—æ®µåï¼‰
  - DTO åˆ›å»ºå¤±è´¥ â†’ ScraperParsingError
  - æ—¥æœŸè§£æå¤±è´¥ â†’ è®°å½•è­¦å‘Šå¹¶ç»§ç»­ï¼ˆä¸ä¸­æ–­ï¼‰

âœ… scrape() æ–¹æ³•ï¼š
  - æ•è·å¹¶åˆ†ç±»ä¸‰ç§é”™è¯¯ï¼šéªŒè¯é”™è¯¯ã€è§£æé”™è¯¯ã€å…¶ä»–
  - è¯¦ç»†çš„æ—¥å¿—è®°å½•ï¼ˆé”™è¯¯ç±»å‹ç»Ÿè®¡ï¼‰
  - è‡´å‘½é”™è¯¯å‘ä¸Šä¼ é€’ï¼Œéè‡´å‘½é”™è¯¯è·³è¿‡
```

**æµ‹è¯•æ›´æ–°:**
```python
# tests/test_seek_adapter.py - æ›´æ–°æµ‹è¯•
âœ… test_transform_job_missing_id()     # éªŒè¯ ScraperValidationError
âœ… test_transform_job_missing_title()  # éªŒè¯ ScraperValidationError
```

**æˆåŠŸæ ‡å‡†:**
- âœ… å®šä¹‰ 11 ä¸ªè‡ªå®šä¹‰å¼‚å¸¸ç±»ï¼ˆè¶…å‡ºé¢„æœŸ 3-5 ä¸ªï¼‰
- âœ… åœ¨ SeekAdapter ä¸­å…¨é¢ä½¿ç”¨
- âœ… æ›´æ–°å•å…ƒæµ‹è¯•ï¼ˆ2 ä¸ªæµ‹è¯•éªŒè¯å¼‚å¸¸è¡Œä¸ºï¼‰
- âœ… æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼ˆ92/92 = 100%ï¼‰

**å®ç°äº®ç‚¹:**
- å®Œæ•´çš„å¼‚å¸¸å±‚æ¬¡ç»“æ„ï¼ˆåŸºç±» + ç»§æ‰¿ï¼‰
- æ¯ä¸ªå¼‚å¸¸ç±»æºå¸¦ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼ˆplatform, field, status_code ç­‰ï¼‰
- `classify_http_error()` è¾…åŠ©å‡½æ•°è‡ªåŠ¨åˆ†ç±» HTTP é”™è¯¯
- é”™è¯¯æ—¥å¿—åŒ…å«ç»Ÿè®¡ä¿¡æ¯ï¼ˆéªŒè¯é”™è¯¯ã€è§£æé”™è¯¯ã€å…¶ä»–ï¼‰

**æ”¶ç›Š:**
- âœ… æ›´ç²¾å‡†çš„é”™è¯¯æ—¥å¿—ï¼ˆåŒºåˆ† 11 ç§é”™è¯¯ç±»å‹ï¼‰
- âœ… æ›´å¥½çš„ API å“åº”ï¼ˆè¿”å›å…·ä½“é”™è¯¯ä¿¡æ¯ï¼‰
- âœ… ä¾¿äºè°ƒè¯•å’Œé—®é¢˜æ’æŸ¥
- âœ… å±•ç¤ºé”™è¯¯å¤„ç†çš„æ·±åº¦ç†è§£å’Œæœ€ä½³å®è·µ

---

#### 1.3 åœ°ç‚¹è§£æå¢å¼º âœ…

**çŠ¶æ€:** å·²å®Œæˆ
**å®é™…æ—¶é—´:** 30 åˆ†é’Ÿ
**å®Œæˆæ—¶é—´:** 2025-12-21

**ä»»åŠ¡æè¿°:**
- å½“å‰ `parse_location()` åªæ”¯æŒç®€å•æ ¼å¼ï¼ˆ"Sydney, NSW"ï¼‰
- æ— æ³•å¤„ç†å¤æ‚æ ¼å¼ï¼ˆ"Toowoomba & Darling Downs QLD"ï¼‰

**å·²å®Œæˆä»»åŠ¡:**
```python
# app/utils/location_parser.py - å¢å¼ºåœ°ç‚¹è§£æï¼ˆä» 54 è¡Œ â†’ 136 è¡Œï¼‰
âœ… æ”¯æŒ & è¿æ¥çš„å¤šåœ°ç‚¹ï¼š
   - "Toowoomba & Darling Downs QLD" â†’ ("QLD", "Toowoomba")
   - "Brisbane & Gold Coast, QLD" â†’ ("QLD", "Brisbane")

âœ… æ”¯æŒ Greater å‰ç¼€ï¼š
   - "Greater Sydney, NSW" â†’ ("NSW", "Sydney")
   - "Greater Sydney Area" â†’ (None, "Sydney")

âœ… æ”¯æŒ Remote ç‰¹æ®Šæƒ…å†µï¼š
   - "Remote - Australia" â†’ ("", "Remote")
   - "Remote, NSW" â†’ ("NSW", "Remote")

âœ… æ”¯æŒ All Australiaï¼š
   - "All Australia" â†’ ("", "All Australia")

âœ… æ”¯æŒæœ«å°¾å·ç¼©å†™æ ¼å¼ï¼ˆæ— é€—å·ï¼‰ï¼š
   - "Toowoomba & Darling Downs QLD" â†’ è‡ªåŠ¨æå– "QLD"
   - ä½¿ç”¨ AUSTRALIAN_STATES å¸¸é‡éªŒè¯å·ç¼©å†™

âœ… æ–°å¢å·¥å…·å‡½æ•°ï¼š
   - _remove_greater_prefix() - ç§»é™¤ "Greater " å‰ç¼€
```

**æµ‹è¯•è¦†ç›–:**
```python
# tests/test_location_parser.py - æ–°å¢ 8 ä¸ªæµ‹è¯•
âœ… test_parse_location_with_ampersand()         # & è¿æ¥ + æœ«å°¾å·ç¼©å†™
âœ… test_parse_location_with_ampersand_comma()   # & è¿æ¥ + é€—å·åˆ†éš”
âœ… test_parse_location_greater_prefix()          # Greater å‰ç¼€ï¼ˆæ— å·ï¼‰
âœ… test_parse_location_greater_with_state()      # Greater å‰ç¼€ + å·
âœ… test_parse_location_remote()                  # Remote - Australia
âœ… test_parse_location_remote_with_state()       # Remote, NSW
âœ… test_parse_location_all_australia()           # All Australia
âœ… test_parse_location_multiple_regions()        # å¤šåœ°åŒº
```

**æˆåŠŸæ ‡å‡†:**
- âœ… æ”¯æŒ "&" è¿æ¥çš„å¤šåœ°ç‚¹ï¼ˆå–ç¬¬ä¸€ä¸ªï¼‰
- âœ… æ”¯æŒ "Greater" å‰ç¼€è‡ªåŠ¨ç§»é™¤
- âœ… æ”¯æŒ "Remote" å’Œ "All Australia" ç‰¹æ®Šæƒ…å†µ
- âœ… æ–°å¢ 8 ä¸ªå•å…ƒæµ‹è¯•
- âœ… æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼ˆ100/100 = 100%ï¼‰

**æµ‹è¯•è¦†ç›–æå‡:**
- æ€»æµ‹è¯•æ•°ï¼š92 â†’ 100 (+8)
- location_parser æµ‹è¯•ï¼š6 â†’ 14 (+8)
- æ‰§è¡Œæ—¶é—´ï¼š0.40 ç§’
- é€šè¿‡ç‡ï¼š100%

**å®ç°äº®ç‚¹:**
- æ¸è¿›å¼è§£æï¼šé€—å·åˆ†éš” â†’ æœ«å°¾å·ç¼©å†™ â†’ ç‰¹æ®Šæ ¼å¼
- çµæ´»çš„æ ¼å¼æ”¯æŒï¼ˆæœ‰æ— é€—å·å‡å¯ï¼‰
- æ¾³å¤§åˆ©äºšå·/é¢†åœ°ç¼©å†™éªŒè¯ï¼ˆ8 ä¸ªå·ï¼‰
- ä¿æŒå‘åå…¼å®¹ï¼ˆåŸæœ‰ 6 ä¸ªæµ‹è¯•å…¨éƒ¨é€šè¿‡ï¼‰

**æ”¶ç›Š:**
- âœ… æå‡æ•°æ®è´¨é‡ï¼ˆåœ°ç‚¹å­—æ®µæ›´å‡†ç¡®ï¼Œè¦†ç›–å¤æ‚æ ¼å¼ï¼‰
- âœ… å‡å°‘æ•°æ®æ¸…æ´—å·¥ä½œ
- âœ… è¾ƒå°æ”¹åŠ¨ï¼Œæ”¶ç›Šæ˜¾è‘—

---

### P2 - æ€§èƒ½ä¼˜åŒ– (Nice-to-Have)

#### 2.1 ç¼“å­˜æœºåˆ¶ ğŸ”–

**çŠ¶æ€:** å¾…è¯„ä¼°
**é¢„è®¡æ—¶é—´:** 2-3 å°æ—¶
**ä¼˜å…ˆçº§:** ä¸­ï¼ˆæ ¹æ®å®é™…ä½¿ç”¨æƒ…å†µè¯„ä¼°ï¼‰

**ä»»åŠ¡æè¿°:**
- å½“å‰æ¯æ¬¡æœç´¢éƒ½è°ƒç”¨å¤–éƒ¨ APIï¼ˆSEEK/Indeedï¼‰
- ç›¸åŒæœç´¢æ¡ä»¶é‡å¤è°ƒç”¨æµªè´¹èµ„æºï¼Œå¯èƒ½è¢«é™æµ

**æ–¹æ¡ˆè®¾è®¡:**

**é€‰é¡¹ A: ç®€å•å†…å­˜ç¼“å­˜ï¼ˆæ¨èç”¨äºå­¦ä¹ /æµ‹è¯•ï¼‰**
```python
# app/services/cache_service.py
class SimpleCache:
    """å†…å­˜ç¼“å­˜ï¼Œé€‚åˆå•æœºéƒ¨ç½²"""

    def __init__(self, ttl_minutes=30):
        self._cache = {}
        self._ttl = timedelta(minutes=ttl_minutes)

    def get(self, key: str) -> Optional[List[JobPostingDTO]]:
        if key in self._cache:
            data, timestamp = self._cache[key]
            if datetime.now() - timestamp < self._ttl:
                return data
        return None

    def set(self, key: str, value: List[JobPostingDTO]):
        self._cache[key] = (value, datetime.now())

# ä½¿ç”¨æ–¹å¼
cache = SimpleCache(ttl_minutes=30)

@app.post("/scrape/seek")
def scrape_seek(request: ScrapeRequest):
    cache_key = generate_cache_key(request.keywords, request.location)
    cached = cache.get(cache_key)
    if cached:
        logger.info(f"ç¼“å­˜å‘½ä¸­: {cache_key}")
        return {"jobs": cached, "from_cache": True}

    jobs = adapter.scrape(request)
    cache.set(cache_key, jobs)
    return {"jobs": jobs, "from_cache": False}
```

**é€‰é¡¹ B: Redis ç¼“å­˜ï¼ˆæ¨èç”¨äºç”Ÿäº§ç¯å¢ƒï¼‰**
```python
# app/services/redis_cache.py
import redis
import json

class RedisCache:
    """Redis ç¼“å­˜ï¼Œé€‚åˆåˆ†å¸ƒå¼éƒ¨ç½²"""

    def __init__(self, redis_url: str, ttl_seconds=1800):
        self.client = redis.from_url(redis_url)
        self.ttl = ttl_seconds

    def get(self, key: str) -> Optional[List[JobPostingDTO]]:
        data = self.client.get(key)
        if data:
            return [JobPostingDTO(**job) for job in json.loads(data)]
        return None

    def set(self, key: str, value: List[JobPostingDTO]):
        serialized = json.dumps([job.dict() for job in value])
        self.client.setex(key, self.ttl, serialized)

# é…ç½®ï¼ˆæ·»åŠ åˆ° .envï¼‰
REDIS_URL=redis://localhost:6379/0
CACHE_TTL_SECONDS=1800  # 30 åˆ†é’Ÿ
```

**å®æ–½æ­¥éª¤:**
1. [ ] å®ç° SimpleCache ç±»ï¼ˆå…ˆç®€å•å®ç°ï¼‰
2. [ ] æ·»åŠ ç¼“å­˜ key ç”Ÿæˆé€»è¾‘ï¼ˆMD5 hashï¼‰
3. [ ] åœ¨ FastAPI ç«¯ç‚¹ä¸­é›†æˆ
4. [ ] æµ‹è¯•ç¼“å­˜å‘½ä¸­ç‡
5. [ ] ï¼ˆå¯é€‰ï¼‰å‡çº§ä¸º Redis ç¼“å­˜

**æˆåŠŸæ ‡å‡†:**
- [ ] ç›¸åŒæœç´¢æ¡ä»¶è¿”å›ç¼“å­˜æ•°æ®
- [ ] TTL è¿‡æœŸåè‡ªåŠ¨åˆ·æ–°
- [ ] æ·»åŠ ç¼“å­˜ç»Ÿè®¡ï¼ˆå‘½ä¸­ç‡ã€ç¼“å­˜å¤§å°ï¼‰

**æ”¶ç›Š:**
- å‡å°‘ 50-80% çš„å¤–éƒ¨ API è°ƒç”¨ï¼ˆå‡è®¾æœ‰é‡å¤æœç´¢ï¼‰
- é™ä½è¢«é™æµé£é™©
- æå‡å“åº”é€Ÿåº¦ï¼ˆç¼“å­˜å“åº” < 50ms vs API å“åº” 1-3sï¼‰

**æƒè¡¡åˆ†æ:**
- **ä½•æ—¶å®æ–½?** å¦‚æœåŒä¸€æœç´¢æ¡ä»¶é¢‘ç¹é‡å¤ï¼ˆå¦‚æ¼”ç¤ºã€æµ‹è¯•ï¼‰ï¼Œç«‹å³å®æ–½
- **ä½•æ—¶å»¶å?** å¦‚æœæ¯æ¬¡æœç´¢æ¡ä»¶éƒ½ä¸åŒï¼Œç¼“å­˜æ”¶ç›Šä½ï¼Œå¯å»¶å

---

#### 2.2 å¹¶å‘æŠ“å– ğŸ”–

**çŠ¶æ€:** å¾…è¯„ä¼°
**é¢„è®¡æ—¶é—´:** 2-3 å°æ—¶
**ä¼˜å…ˆçº§:** ä½ï¼ˆå½“å‰å•æ¬¡æŠ“å–å¤Ÿå¿«ï¼‰

**ä»»åŠ¡æè¿°:**
- å½“å‰æŠ“å–æ˜¯ä¸²è¡Œçš„ï¼ˆä¸€ä¸ªæ¥ä¸€ä¸ªï¼‰
- å¦‚æœéœ€è¦åŒæ—¶æŠ“å–å¤šä¸ªæ•°æ®æºï¼Œæ€§èƒ½è¾ƒæ…¢

**æ–¹æ¡ˆè®¾è®¡:**
```python
# app/services/concurrent_scraper.py
import asyncio
from typing import List

class ConcurrentScraper:
    """å¹¶å‘æŠ“å–å¤šä¸ªæ•°æ®æº"""

    async def scrape_all(self, request: ScrapeRequest) -> List[JobPostingDTO]:
        tasks = [
            self._scrape_indeed(request),
            self._scrape_seek(request),
        ]

        results = await asyncio.gather(*tasks, return_exceptions=True)

        # åˆå¹¶ç»“æœ
        jobs = []
        for result in results:
            if isinstance(result, list):
                jobs.extend(result)
            else:
                logger.error(f"æŠ“å–å¤±è´¥: {result}")

        return jobs

    async def _scrape_indeed(self, request: ScrapeRequest):
        adapter = IndeedAdapter()
        return await asyncio.to_thread(adapter.scrape, request)

    async def _scrape_seek(self, request: ScrapeRequest):
        adapter = SeekAdapter()
        return await asyncio.to_thread(adapter.scrape, request)

# FastAPI ç«¯ç‚¹
@app.post("/scrape/all")
async def scrape_all_sources(request: ScrapeRequest):
    scraper = ConcurrentScraper()
    jobs = await scraper.scrape_all(request)
    return {"jobs": jobs, "count": len(jobs)}
```

**å®æ–½æ­¥éª¤:**
1. [ ] åˆ›å»º ConcurrentScraper ç±»
2. [ ] ä½¿ç”¨ asyncio.gather å¹¶å‘è°ƒç”¨
3. [ ] å¤„ç†éƒ¨åˆ†å¤±è´¥æƒ…å†µï¼ˆä¸€ä¸ªæºå¤±è´¥ä¸å½±å“å…¶ä»–ï¼‰
4. [ ] æ€§èƒ½æµ‹è¯•ï¼ˆå¯¹æ¯”ä¸²è¡Œ vs å¹¶å‘ï¼‰

**æˆåŠŸæ ‡å‡†:**
- [ ] åŒæ—¶æŠ“å– 2 ä¸ªæºæ¯”ä¸²è¡Œå¿« 40-60%
- [ ] å•ä¸ªæºå¤±è´¥ä¸å½±å“å…¶ä»–æº
- [ ] æ—¥å¿—è®°å½•æ¯ä¸ªæºçš„è€—æ—¶

**æ”¶ç›Š:**
- æå‡å¤šæºæŠ“å–æ€§èƒ½ï¼ˆ2 ä¸ªæº 3s â†’ 1.5sï¼‰
- æ›´å¥½çš„ç”¨æˆ·ä½“éªŒ

**æƒè¡¡åˆ†æ:**
- **ä½•æ—¶å®æ–½?** å¦‚æœéœ€è¦åŒæ—¶æŠ“å– 3+ ä¸ªæ•°æ®æº
- **ä½•æ—¶å»¶å?** å¦‚æœåªä½¿ç”¨å•ä¸€æ•°æ®æºï¼Œæ”¶ç›Šä¸å¤§

---

#### 2.3 æ‰¹é‡æŠ“å–ä¼˜åŒ– ğŸ”–

**çŠ¶æ€:** å¾…è¯„ä¼°
**é¢„è®¡æ—¶é—´:** 2 å°æ—¶
**ä¼˜å…ˆçº§:** ä½

**ä»»åŠ¡æè¿°:**
- å½“å‰ API åªæ”¯æŒå•æ¬¡æŠ“å–ï¼ˆmax_results=50ï¼‰
- å¦‚æœéœ€è¦æŠ“å– 200 ä¸ªç»“æœï¼Œéœ€è¦è°ƒç”¨ 4 æ¬¡ API

**æ–¹æ¡ˆè®¾è®¡:**
```python
# æ”¯æŒåˆ†é¡µæŠ“å–
@app.post("/scrape/seek/batch")
def scrape_seek_batch(request: ScrapeRequest):
    """
    æ‰¹é‡æŠ“å–ï¼Œæ”¯æŒåˆ†é¡µ

    request.max_results = 200 â†’ è‡ªåŠ¨åˆ† 4 æ¬¡è°ƒç”¨ï¼ˆæ¯æ¬¡ 50ï¼‰
    """
    adapter = SeekAdapter()
    total_wanted = request.max_results or 50
    batch_size = 50  # SEEK API æ¯é¡µæœ€å¤š 50

    all_jobs = []
    for page in range(1, (total_wanted // batch_size) + 1):
        batch_request = ScrapeRequest(
            keywords=request.keywords,
            location=request.location,
            max_results=batch_size
        )
        jobs = adapter.scrape(batch_request)
        all_jobs.extend(jobs)

        if len(jobs) < batch_size:
            break  # æ²¡æœ‰æ›´å¤šç»“æœ

    return {"jobs": all_jobs[:total_wanted], "count": len(all_jobs)}
```

**æˆåŠŸæ ‡å‡†:**
- [ ] æ”¯æŒæŠ“å–è¶…è¿‡ 50 ä¸ªç»“æœ
- [ ] è‡ªåŠ¨åˆ†é¡µè°ƒç”¨
- [ ] æ·»åŠ è¿›åº¦åé¦ˆï¼ˆå¦‚ WebSocketï¼‰

**æ”¶ç›Š:**
- æ”¯æŒå¤§è§„æ¨¡æ•°æ®é‡‡é›†
- é€‚åˆåå°ä»»åŠ¡ï¼ˆHangfire ScrapeJobï¼‰

---

#### 2.4 ç»“æ„åŒ–æ—¥å¿— ğŸ”–

**çŠ¶æ€:** å¾…è¯„ä¼°
**é¢„è®¡æ—¶é—´:** 1 å°æ—¶
**ä¼˜å…ˆçº§:** ä½ï¼ˆå½“å‰æ—¥å¿—å¤Ÿç”¨ï¼‰

**ä»»åŠ¡æè¿°:**
- å½“å‰ä½¿ç”¨ Python loggingï¼ˆæ–‡æœ¬æ ¼å¼ï¼‰
- éš¾ä»¥èšåˆå’Œåˆ†æï¼ˆå¦‚ç»Ÿè®¡æˆåŠŸç‡ã€å¹³å‡è€—æ—¶ï¼‰

**æ–¹æ¡ˆè®¾è®¡:**
```python
# ä½¿ç”¨ structlog å®ç°ç»“æ„åŒ–æ—¥å¿—
import structlog

logger = structlog.get_logger()

# è®°å½•æŠ“å–äº‹ä»¶
logger.info(
    "scrape_completed",
    platform="seek",
    keywords="plumber",
    results_count=5,
    duration_ms=1234,
    cache_hit=False
)

# è¾“å‡ºæ ¼å¼ï¼ˆJSONï¼‰
{
  "event": "scrape_completed",
  "platform": "seek",
  "keywords": "plumber",
  "results_count": 5,
  "duration_ms": 1234,
  "cache_hit": false,
  "timestamp": "2025-12-20T10:30:00Z"
}
```

**é›†æˆ Elasticsearchï¼ˆå¯é€‰ï¼‰:**
```python
# å°†æ—¥å¿—å‘é€åˆ° Elasticsearch
# å¯ä»¥ä½¿ç”¨ Kibana å¯è§†åŒ–åˆ†æ
# - æŒ‰å¹³å°ç»Ÿè®¡æˆåŠŸç‡
# - æŒ‰å…³é”®è¯ç»Ÿè®¡çƒ­é—¨æœç´¢
# - ç›‘æ§ API å“åº”æ—¶é—´
```

**æˆåŠŸæ ‡å‡†:**
- [ ] æ‰€æœ‰æ—¥å¿—ä½¿ç”¨ç»“æ„åŒ–æ ¼å¼
- [ ] å¯ä»¥æŒ‰å­—æ®µè¿‡æ»¤å’Œèšåˆ
- [ ] ï¼ˆå¯é€‰ï¼‰é›†æˆ Elasticsearch/Datadog

**æ”¶ç›Š:**
- æ›´å¥½çš„å¯è§‚æµ‹æ€§ï¼ˆObservabilityï¼‰
- å¿«é€Ÿæ’æŸ¥é—®é¢˜
- æ•°æ®é©±åŠ¨å†³ç­–ï¼ˆå¦‚è¯†åˆ«çƒ­é—¨æœç´¢ï¼‰

---

#### 2.5 ç›‘æ§å’Œå‘Šè­¦ ğŸ”–

**çŠ¶æ€:** å¾…è¯„ä¼°
**é¢„è®¡æ—¶é—´:** 2 å°æ—¶
**ä¼˜å…ˆçº§:** ä½ï¼ˆé€‚åˆç”Ÿäº§ç¯å¢ƒï¼‰

**ä»»åŠ¡æè¿°:**
- å½“å‰æ²¡æœ‰ç›‘æ§ç³»ç»Ÿ
- æ— æ³•çŸ¥é“ API æˆåŠŸç‡ã€å“åº”æ—¶é—´ç­‰æŒ‡æ ‡

**æ–¹æ¡ˆè®¾è®¡:**
```python
# ä½¿ç”¨ Prometheus + Grafana

# 1. æ·»åŠ  metrics ç«¯ç‚¹
from prometheus_client import Counter, Histogram, generate_latest

scrape_requests_total = Counter(
    "scrape_requests_total",
    "Total scrape requests",
    ["platform", "status"]
)

scrape_duration_seconds = Histogram(
    "scrape_duration_seconds",
    "Scrape duration",
    ["platform"]
)

@app.get("/metrics")
def metrics():
    return Response(generate_latest(), media_type="text/plain")

# 2. åœ¨é€‚é…å™¨ä¸­è®°å½•æŒ‡æ ‡
def scrape(self, request: ScrapeRequest):
    start_time = time.time()
    try:
        jobs = self._do_scrape(request)
        scrape_requests_total.labels(platform="seek", status="success").inc()
        return jobs
    except Exception as e:
        scrape_requests_total.labels(platform="seek", status="error").inc()
        raise
    finally:
        duration = time.time() - start_time
        scrape_duration_seconds.labels(platform="seek").observe(duration)
```

**Grafana ä»ªè¡¨æ¿:**
- æ€»è¯·æ±‚æ•°ï¼ˆæŒ‰å¹³å°ï¼‰
- æˆåŠŸç‡ï¼ˆæˆåŠŸ/æ€»æ•°ï¼‰
- å¹³å‡å“åº”æ—¶é—´
- ç¼“å­˜å‘½ä¸­ç‡

**æˆåŠŸæ ‡å‡†:**
- [ ] Prometheus æ­£ç¡®æ”¶é›†æŒ‡æ ‡
- [ ] Grafana ä»ªè¡¨æ¿å¯è§†åŒ–
- [ ] è®¾ç½®å‘Šè­¦è§„åˆ™ï¼ˆå¦‚æˆåŠŸç‡ < 90%ï¼‰

**æ”¶ç›Š:**
- å®æ—¶ç›‘æ§ç³»ç»Ÿå¥åº·åº¦
- å¿«é€Ÿå‘ç°å¼‚å¸¸ï¼ˆå¦‚ API é™æµï¼‰
- å±•ç¤º SRE/DevOps èƒ½åŠ›

---

### P3 - åŠŸèƒ½æ‰©å±• (Future)

#### 3.1 æ–°æ•°æ®æº - LinkedIn ğŸ”–

**çŠ¶æ€:** å¾…è°ƒç ”
**é¢„è®¡æ—¶é—´:** 4-6 å°æ—¶
**ä¼˜å…ˆçº§:** V2 åŠŸèƒ½

**ä»»åŠ¡æè¿°:**
- æ¥å…¥ LinkedIn Jobs API æˆ–çˆ¬è™«
- æ‰©å±•èŒä½æ•°æ®è¦†ç›–èŒƒå›´

**è°ƒç ”ä»»åŠ¡:**
1. [ ] LinkedIn æ˜¯å¦æœ‰å…¬å¼€ APIï¼Ÿ
2. [ ] æ˜¯å¦éœ€è¦ä½¿ç”¨çˆ¬è™«ï¼Ÿï¼ˆæ³•å¾‹é£é™©è¯„ä¼°ï¼‰
3. [ ] æ•°æ®æ ¼å¼å’Œå­—æ®µæ˜ å°„

**å®æ–½æ­¥éª¤:**
1. [ ] åˆ›å»º LinkedInAdapter ç±»
2. [ ] å®ç° scrape() æ–¹æ³•
3. [ ] æ•°æ®è½¬æ¢ä¸º JobPostingDTO
4. [ ] æ·»åŠ å•å…ƒæµ‹è¯•
5. [ ] FastAPI ç«¯ç‚¹é›†æˆ

**æ”¶ç›Š:**
- æ›´å¤šèŒä½æ•°æ®
- å±•ç¤ºæ¶æ„æ‰©å±•æ€§ï¼ˆadapter æ¨¡å¼çš„ä¼˜åŠ¿ï¼‰

---

#### 3.2 æ–°æ•°æ®æº - Glassdoor ğŸ”–

**çŠ¶æ€:** å¾…è°ƒç ”
**é¢„è®¡æ—¶é—´:** 4-6 å°æ—¶
**ä¼˜å…ˆçº§:** V2 åŠŸèƒ½

**ä»»åŠ¡æè¿°:**
- æ¥å…¥ Glassdoor Jobs API æˆ–çˆ¬è™«
- ç‰¹è‰²æ•°æ®ï¼šå…¬å¸è¯„åˆ†ã€è–ªèµ„é€æ˜åº¦

**è°ƒç ”ä»»åŠ¡:**
åŒ LinkedIn

---

#### 3.3 AI è¯­ä¹‰æœç´¢ ğŸ”–

**çŠ¶æ€:** å¾…è°ƒç ”
**é¢„è®¡æ—¶é—´:** 8-12 å°æ—¶
**ä¼˜å…ˆçº§:** V2 åŠŸèƒ½ï¼ˆéœ€è¦æ•°æ®åº“æ”¯æŒï¼‰

**ä»»åŠ¡æè¿°:**
- å½“å‰æœç´¢æ˜¯å…³é”®è¯åŒ¹é…ï¼ˆ"plumber" åªåŒ¹é… "plumber"ï¼‰
- AI è¯­ä¹‰æœç´¢å¯ä»¥åŒ¹é…ç›¸ä¼¼èŒä½ï¼ˆ"plumber" â†’ "pipefitter", "gasfitter"ï¼‰

**æ–¹æ¡ˆè®¾è®¡:**
```python
# 1. ä½¿ç”¨ pgvector å­˜å‚¨èŒä½åµŒå…¥
# PostgreSQL æ‰©å±•ï¼Œæ”¯æŒå‘é‡æœç´¢

# 2. ç”ŸæˆèŒä½åµŒå…¥
from sentence_transformers import SentenceTransformer

model = SentenceTransformer('all-MiniLM-L6-v2')
embedding = model.encode(job.title + " " + job.description)

# 3. å­˜å‚¨åˆ°æ•°æ®åº“
# jobs è¡¨æ·»åŠ  embedding åˆ—ï¼ˆvector ç±»å‹ï¼‰

# 4. è¯­ä¹‰æœç´¢
query_embedding = model.encode("plumber jobs")
similar_jobs = db.query(
    "SELECT * FROM jobs ORDER BY embedding <-> %s LIMIT 10",
    query_embedding
)
```

**å®æ–½æ­¥éª¤:**
1. [ ] è°ƒç ” pgvector æˆ– Elasticsearch
2. [ ] é€‰æ‹©åµŒå…¥æ¨¡å‹ï¼ˆSentenceTransformerï¼‰
3. [ ] ç”Ÿæˆæ‰€æœ‰èŒä½çš„åµŒå…¥
4. [ ] å®ç°è¯­ä¹‰æœç´¢ API
5. [ ] æ€§èƒ½æµ‹è¯•ï¼ˆå‘é‡æœç´¢ vs å…³é”®è¯æœç´¢ï¼‰

**æ”¶ç›Š:**
- æ›´æ™ºèƒ½çš„æœç´¢ä½“éªŒ
- å±•ç¤º AI/ML èƒ½åŠ›
- å­¦ä¹ å‘é‡æ•°æ®åº“

**å‰ç½®æ¡ä»¶:**
- éœ€è¦ .NET åç«¯æ”¯æŒï¼ˆpgvector æ‰©å±•ï¼‰
- éœ€è¦ä¸€å®šé‡çš„èŒä½æ•°æ®ï¼ˆè‡³å°‘ 1000+ï¼‰

---

## ğŸ—ï¸ .NET åç«¯æœåŠ¡ä¼˜åŒ–ä»»åŠ¡

### P1 - é›†æˆæµ‹è¯• (Important)

#### 1.1 Python â†” .NET é›†æˆæµ‹è¯• â³

**çŠ¶æ€:** å¾…å¼€å§‹
**é¢„è®¡æ—¶é—´:** 2-3 å°æ—¶
**ä¼˜å…ˆçº§:** é«˜ï¼ˆæ ¸å¿ƒåŠŸèƒ½éªŒè¯ï¼‰

**ä»»åŠ¡æè¿°:**
- éªŒè¯ Python FastAPI å’Œ .NET Backend çš„æ•°æ®æµ
- ç¡®ä¿å»é‡é€»è¾‘å’Œæ ‡å‡†åŒ–æ­£ç¡®å·¥ä½œ

**æµ‹è¯•åœºæ™¯:**
```csharp
// åœºæ™¯ 1: æ­£å¸¸æŠ“å–å’Œå­˜å‚¨
[Test]
public async Task TestIngestionPipeline_Success()
{
    // 1. è°ƒç”¨ Python API æŠ“å–èŒä½
    var jobs = await _scrapeApiClient.ScrapeSeekAsync("plumber", maxResults: 5);

    // 2. éªŒè¯è¿”å›æ•°æ®
    Assert.That(jobs.Count, Is.GreaterThan(0));

    // 3. é€šè¿‡ IngestionPipeline å¤„ç†
    await _ingestionPipeline.IngestJobsAsync(jobs);

    // 4. éªŒè¯æ•°æ®åº“å­˜å‚¨
    var dbJobs = await _jobRepository.GetRecentJobsAsync(limit: 10);
    Assert.That(dbJobs.Count, Is.GreaterThan(0));
}

// åœºæ™¯ 2: å»é‡é€»è¾‘
[Test]
public async Task TestDeduplication_SameJob()
{
    // 1. ç¬¬ä¸€æ¬¡æ‘„å–
    await _ingestionPipeline.IngestJobsAsync(jobs);
    var count1 = await _jobRepository.CountAsync();

    // 2. ç¬¬äºŒæ¬¡æ‘„å–ç›¸åŒæ•°æ®
    await _ingestionPipeline.IngestJobsAsync(jobs);
    var count2 = await _jobRepository.CountAsync();

    // 3. éªŒè¯æ²¡æœ‰é‡å¤å­˜å‚¨
    Assert.That(count1, Is.EqualTo(count2));
}

// åœºæ™¯ 3: æ•°æ®æ ‡å‡†åŒ–
[Test]
public async Task TestNormalization_LocationState()
{
    // éªŒè¯åœ°ç‚¹å­—æ®µæ­£ç¡®åˆ†ç¦»ï¼ˆSuburb vs Stateï¼‰
    var job = await _jobRepository.GetByIdAsync(jobId);
    Assert.That(job.LocationState, Is.EqualTo("NSW"));
    Assert.That(job.LocationSuburb, Is.EqualTo("Sydney"));
}
```

**æˆåŠŸæ ‡å‡†:**
- [ ] è‡³å°‘ 5 ä¸ªé›†æˆæµ‹è¯•è¦†ç›–æ ¸å¿ƒæµç¨‹
- [ ] æ‰€æœ‰æµ‹è¯•é€šè¿‡
- [ ] éªŒè¯å»é‡é€»è¾‘æ­£ç¡®

**æ”¶ç›Š:**
- ç¡®ä¿ç³»ç»Ÿç«¯åˆ°ç«¯å¯ç”¨
- å‘ç°æ½œåœ¨çš„æ•°æ®è½¬æ¢é—®é¢˜
- é¢è¯•æ—¶å¯ä»¥å±•ç¤ºå®Œæ•´çš„æµ‹è¯•ç­–ç•¥

---

### P2 - æ€§èƒ½ä¼˜åŒ– (Nice-to-Have)

#### 2.1 .NET åç«¯ç¼“å­˜ ğŸ”–

**çŠ¶æ€:** å¾…è¯„ä¼°
**é¢„è®¡æ—¶é—´:** 2-3 å°æ—¶
**ä¼˜å…ˆçº§:** ä½ï¼ˆPython å±‚ç¼“å­˜å·²è¶³å¤Ÿï¼‰

**ä»»åŠ¡æè¿°:**
- åœ¨ .NET åç«¯æ·»åŠ  Redis ç¼“å­˜
- ç¼“å­˜æŸ¥è¯¢ API çš„å“åº”ï¼ˆå¦‚çƒ­é—¨æœç´¢ï¼‰

**æ–¹æ¡ˆè®¾è®¡:**
```csharp
// ä½¿ç”¨ IDistributedCache
public class JobsController : ControllerBase
{
    private readonly IDistributedCache _cache;

    [HttpGet]
    public async Task<IActionResult> SearchJobs([FromQuery] JobSearchRequest request)
    {
        var cacheKey = $"search:{request.Trade}:{request.Location}";

        // å°è¯•ä»ç¼“å­˜è·å–
        var cachedData = await _cache.GetStringAsync(cacheKey);
        if (cachedData != null)
        {
            var cachedJobs = JsonSerializer.Deserialize<List<JobDto>>(cachedData);
            return Ok(new { jobs = cachedJobs, fromCache = true });
        }

        // ä»æ•°æ®åº“æŸ¥è¯¢
        var jobs = await _jobRepository.SearchJobsAsync(request);

        // ç¼“å­˜ç»“æœï¼ˆ5 åˆ†é’Ÿï¼‰
        var options = new DistributedCacheEntryOptions
        {
            AbsoluteExpirationRelativeToNow = TimeSpan.FromMinutes(5)
        };
        await _cache.SetStringAsync(cacheKey, JsonSerializer.Serialize(jobs), options);

        return Ok(new { jobs, fromCache = false });
    }
}
```

**æˆåŠŸæ ‡å‡†:**
- [ ] é…ç½® Redis
- [ ] çƒ­é—¨æŸ¥è¯¢å“åº”æ—¶é—´ < 50ms
- [ ] æ·»åŠ ç¼“å­˜ç»Ÿè®¡ç«¯ç‚¹

**æ”¶ç›Š:**
- å‡è½»æ•°æ®åº“å‹åŠ›
- æå‡æŸ¥è¯¢ API æ€§èƒ½

**æƒè¡¡:**
- å¦‚æœæŸ¥è¯¢ä¸é¢‘ç¹ï¼Œæ”¶ç›Šæœ‰é™
- å»ºè®®å…ˆå®Œæˆ Python å±‚ç¼“å­˜

---

#### 2.2 æ•°æ®åº“ç´¢å¼•ä¼˜åŒ– ğŸ”–

**çŠ¶æ€:** å¾…è¯„ä¼°
**é¢„è®¡æ—¶é—´:** 1 å°æ—¶
**ä¼˜å…ˆçº§:** ä½ï¼ˆæ•°æ®é‡å°æ—¶ä¸æ˜æ˜¾ï¼‰

**ä»»åŠ¡æè¿°:**
- ä¸ºå¸¸ç”¨æŸ¥è¯¢å­—æ®µæ·»åŠ ç´¢å¼•
- æå‡æœç´¢æ€§èƒ½

**æ–¹æ¡ˆè®¾è®¡:**
```csharp
// åœ¨ EF Core é…ç½®ä¸­æ·»åŠ ç´¢å¼•
modelBuilder.Entity<JobPosting>()
    .HasIndex(j => j.Trade);

modelBuilder.Entity<JobPosting>()
    .HasIndex(j => j.LocationState);

modelBuilder.Entity<JobPosting>()
    .HasIndex(j => new { j.Trade, j.LocationState });  // å¤åˆç´¢å¼•

modelBuilder.Entity<JobPosting>()
    .HasIndex(j => j.CreatedAt);
```

**æ€§èƒ½æµ‹è¯•:**
```sql
-- æµ‹è¯•æŸ¥è¯¢æ€§èƒ½
EXPLAIN ANALYZE
SELECT * FROM JobPostings
WHERE Trade = 'Plumber' AND LocationState = 'NSW'
ORDER BY CreatedAt DESC
LIMIT 20;

-- å¯¹æ¯”æœ‰æ— ç´¢å¼•çš„æ‰§è¡Œæ—¶é—´
```

**æˆåŠŸæ ‡å‡†:**
- [ ] æ·»åŠ  3-5 ä¸ªç´¢å¼•
- [ ] æŸ¥è¯¢æ€§èƒ½æå‡ 50%+
- [ ] éªŒè¯ç´¢å¼•æœ‰æ•ˆï¼ˆEXPLAIN ANALYZEï¼‰

**æ”¶ç›Š:**
- æ•°æ®é‡å¢é•¿åä¿æŒæ€§èƒ½
- å­¦ä¹ æ•°æ®åº“ä¼˜åŒ–

**æƒè¡¡:**
- æ•°æ®é‡ < 10,000 æ—¶æ”¶ç›Šä¸å¤§
- ç´¢å¼•è¿‡å¤šä¼šå½±å“å†™å…¥æ€§èƒ½

---

### P3 - åŠŸèƒ½æ‰©å±• (Future)

#### 3.1 ç”¨æˆ·ç³»ç»Ÿï¼ˆV2 åŠŸèƒ½ï¼‰ğŸ”–

**çŠ¶æ€:** V2 è§„åˆ’
**é¢„è®¡æ—¶é—´:** 8-12 å°æ—¶
**ä¼˜å…ˆçº§:** V2

**ä»»åŠ¡åˆ—è¡¨:**
- [ ] ç”¨æˆ·æ³¨å†Œ/ç™»å½•ï¼ˆJWT è®¤è¯ï¼‰
- [ ] ä¿å­˜çš„å·¥ä½œï¼ˆSavedJobs è¡¨ï¼‰
- [ ] å·¥ä½œæé†’ï¼ˆJobAlerts è¡¨ï¼‰
- [ ] ç”¨æˆ·æƒé™ç®¡ç†

**è¯¦ç»†è§„åˆ’:** ç­‰ V1 å®Œæˆååˆ¶å®š

---

#### 3.2 å‰ç«¯åº”ç”¨ï¼ˆV2 åŠŸèƒ½ï¼‰ğŸ”–

**çŠ¶æ€:** V2 è§„åˆ’
**é¢„è®¡æ—¶é—´:** 20-30 å°æ—¶
**ä¼˜å…ˆçº§:** V2

**æŠ€æœ¯æ ˆ:**
- React + TypeScript
- Material-UI / Ant Design
- React Queryï¼ˆæ•°æ®è·å–ï¼‰

**è¯¦ç»†è§„åˆ’:** ç­‰ V1 å®Œæˆååˆ¶å®š

---

## ğŸ“Š å®æ–½å»ºè®®

### å½“å‰é˜¶æ®µï¼ˆ2025-12-20ï¼‰

**å·²å®Œæˆ:**
âœ… Python çˆ¬è™«æ ¸å¿ƒåŠŸèƒ½ï¼ˆ69 ä¸ªæµ‹è¯•é€šè¿‡ï¼‰
âœ… .NET åç«¯ APIï¼ˆ8 ä¸ªç«¯ç‚¹ï¼‰
âœ… æ•°æ®åº“æ¶æ„

**ä¸‹ä¸€æ­¥ï¼ˆæ¨èé¡ºåºï¼‰:**

**é˜¶æ®µ 1: éªŒè¯é›†æˆï¼ˆP1ï¼Œå¿…åšï¼‰**
1. â³ .NET é›†æˆæµ‹è¯•ï¼ˆ2-3 å°æ—¶ï¼‰
   - éªŒè¯ Python â†’ .NET â†’ PostgreSQL æ•°æ®æµ
   - ç¡®ä¿å»é‡å’Œæ ‡å‡†åŒ–æ­£ç¡®
2. â³ SeekAdapter å•å…ƒæµ‹è¯•ï¼ˆ1-2 å°æ—¶ï¼‰
   - è¡¥å……ç¼ºå¤±çš„æµ‹è¯•è¦†ç›–

**é˜¶æ®µ 2: è´¨é‡æå‡ï¼ˆP1ï¼Œå»ºè®®åšï¼‰**
3. â³ é”™è¯¯å¤„ç†ç»†åŒ–ï¼ˆ1 å°æ—¶ï¼‰
   - å®šä¹‰è‡ªå®šä¹‰å¼‚å¸¸ç±»
4. â³ åœ°ç‚¹è§£æå¢å¼ºï¼ˆ30 åˆ†é’Ÿï¼‰
   - å¤„ç†å¤æ‚æ ¼å¼

**é˜¶æ®µ 3: æ€§èƒ½ä¼˜åŒ–ï¼ˆP2ï¼Œå¯é€‰ï¼‰**
5. ğŸ”– ç¼“å­˜æœºåˆ¶ï¼ˆ2-3 å°æ—¶ï¼‰
   - å¦‚æœæœ‰é‡å¤æœç´¢éœ€æ±‚ï¼Œå®æ–½ SimpleCache
6. ğŸ”– ç»“æ„åŒ–æ—¥å¿—ï¼ˆ1 å°æ—¶ï¼‰
   - å¦‚æœéœ€è¦åˆ†æä½¿ç”¨æ•°æ®

**é˜¶æ®µ 4: åŠŸèƒ½æ‰©å±•ï¼ˆP3ï¼ŒV2 è®¡åˆ’ï¼‰**
7. ğŸ”– æ–°æ•°æ®æºï¼ˆLinkedIn/Glassdoorï¼‰
8. ğŸ”– AI è¯­ä¹‰æœç´¢
9. ğŸ”– ç”¨æˆ·ç³»ç»Ÿ + å‰ç«¯

---

### æ—¶é—´æˆæœ¬æ€»è§ˆ

| ä¼˜å…ˆçº§ | æ€»ä»»åŠ¡æ•° | é¢„è®¡æ€»æ—¶é—´ | å»ºè®®å®æ–½æ—¶æœº |
|--------|----------|------------|--------------|
| P1 | 4 | 5-7 å°æ—¶ | ç«‹å³ï¼ˆé›†æˆå‰ï¼‰ |
| P2 | 7 | 12-16 å°æ—¶ | V1 ç¨³å®šå |
| P3 | 5 | 40-60 å°æ—¶ | V2 ç‰ˆæœ¬ |

---

### é¢è¯•å‡†å¤‡å»ºè®®

**å±•ç¤ºé¡¹ç›®æ—¶ï¼ŒæŒ‰ä¼˜å…ˆçº§è®²è¿°:**

1. **P0ï¼ˆæ ¸å¿ƒåŠŸèƒ½ï¼‰:** "æˆ‘å®ç°äº†å®Œæ•´çš„èŒä½çˆ¬è™«ç³»ç»Ÿï¼Œæ”¯æŒ Indeed å’Œ SEEK ä¸¤ä¸ªæ•°æ®æº..."
2. **P1ï¼ˆè´¨é‡ä¿è¯ï¼‰:** "æˆ‘éå¸¸æ³¨é‡ä»£ç è´¨é‡ï¼Œç¼–å†™äº† 69 ä¸ªå•å…ƒæµ‹è¯•ï¼Œè¦†ç›–æ‰€æœ‰å·¥å…·å‡½æ•°..."
3. **P2ï¼ˆæ”¹è¿›ç©ºé—´ï¼‰:** "å¦‚æœæœ‰æ›´å¤šæ—¶é—´ï¼Œæˆ‘ä¼šæ·»åŠ ç¼“å­˜æœºåˆ¶æ¥ä¼˜åŒ–æ€§èƒ½..."
4. **P3ï¼ˆæœªæ¥æ„¿æ™¯ï¼‰:** "æœªæ¥å¯ä»¥æ‰©å±•åˆ° LinkedInï¼Œç”šè‡³å®ç° AI è¯­ä¹‰æœç´¢..."

**å›ç­”"å¦‚æœé‡æ–°åš"é—®é¢˜:**

> "å¦‚æœé‡æ–°åšï¼Œæˆ‘ä¼šä¼˜å…ˆå®Œæˆ P1 çš„ SeekAdapter å•å…ƒæµ‹è¯•å’Œé”™è¯¯å¤„ç†ç»†åŒ–ï¼Œå› ä¸ºè¿™ç›´æ¥å½±å“ç³»ç»Ÿçš„ç¨³å®šæ€§å’Œå¯ç»´æŠ¤æ€§ã€‚P2 çš„ç¼“å­˜æœºåˆ¶å¯ä»¥æ ¹æ®å®é™…ä½¿ç”¨æƒ…å†µè¯„ä¼°ï¼Œå¦‚æœæœç´¢æ¡ä»¶é‡å¤åº¦é«˜ï¼Œå°±å€¼å¾—æŠ•å…¥æ—¶é—´å®ç°ã€‚"

---

## ğŸ”— ç›¸å…³æ–‡æ¡£

- [OPTIMIZATION_PRIORITIES_GUIDE.md](../tutorials/OPTIMIZATION_PRIORITIES_GUIDE.md) - ä¼˜å…ˆçº§æ¦‚å¿µå­¦ä¹ 
- [ARCHITECTURE_DECISIONS.md](./ARCHITECTURE_DECISIONS.md) - æŠ€æœ¯é€‰å‹å’Œæƒè¡¡åˆ†æ
- [NEXT_STEPS.md](./NEXT_STEPS.md) - æ€»ä½“å¼€å‘è·¯çº¿å›¾
- [TDD_DEVELOPMENT_GUIDE.md](../tutorials/TDD_DEVELOPMENT_GUIDE.md) - æµ‹è¯•é©±åŠ¨å¼€å‘æ–¹æ³•

---

**æœ€åæ›´æ–°:** 2025-12-20
**ç»´æŠ¤è€…:** Claude Code
**çŠ¶æ€:** æŒç»­æ›´æ–°ï¼ˆæ¯ä¸ªé˜¶æ®µå®Œæˆåæ›´æ–°è¿›åº¦ï¼‰
