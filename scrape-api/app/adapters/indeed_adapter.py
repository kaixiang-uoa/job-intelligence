"""
Indeed å¹³å°é€‚é…å™¨

ä½¿ç”¨ JobSpy åº“æŠ“å– Indeed èŒä½æ•°æ®å¹¶è½¬æ¢ä¸ºç»Ÿä¸€çš„ JobPostingDTO æ ¼å¼
"""

from typing import List
from datetime import datetime, timezone
from loguru import logger

try:
    from jobspy import scrape_jobs
except ImportError:
    logger.warning("JobSpy library not installed. Indeed scraping will not work.")
    scrape_jobs = None

from app.adapters.base_adapter import BaseJobAdapter, ScraperException
from app.models.job_posting_dto import JobPostingDTO, ScrapeRequest, PlatformEnum
from app.utils.location_parser import parse_location
from app.utils.trade_extractor import extract_trade
from app.utils.employment_type import normalize_employment_type
from app.config.settings import settings


class IndeedAdapter(BaseJobAdapter):
    """
    Indeed å¹³å°é€‚é…å™¨

    ä½¿ç”¨ JobSpy åº“æŠ“å– Indeed èŒä½æ•°æ®
    """

    @property
    def platform_name(self) -> str:
        """å¹³å°åç§°"""
        return "indeed"

    def _deduplicate_by_source_id(self, jobs: List[JobPostingDTO]) -> List[JobPostingDTO]:
        """
        åŸºäº source_id å»é‡

        Args:
            jobs: èŒä½åˆ—è¡¨

        Returns:
            List[JobPostingDTO]: å»é‡åçš„èŒä½åˆ—è¡¨
        """
        seen_ids = set()
        unique_jobs = []

        for job in jobs:
            if job.source_id not in seen_ids:
                seen_ids.add(job.source_id)
                unique_jobs.append(job)
            else:
                logger.debug(f"å‘ç°é‡å¤èŒä½: {job.source_id} - {job.title}")

        return unique_jobs

    def scrape(self, request: ScrapeRequest) -> List[JobPostingDTO]:
        """
        æŠ“å– Indeed èŒä½æ•°æ®

        Args:
            request: æŠ“å–è¯·æ±‚å‚æ•°

        Returns:
            List[JobPostingDTO]: èŒä½æ•°æ®åˆ—è¡¨

        Raises:
            ScraperException: æŠ“å–å¤±è´¥æ—¶æŠ›å‡º
        """
        # éªŒè¯è¯·æ±‚å‚æ•°
        self.validate_request(request)

        # æ£€æŸ¥ JobSpy æ˜¯å¦å¯ç”¨
        if scrape_jobs is None:
            raise ScraperException("JobSpy library is not installed. Please run: pip install python-jobspy")

        logger.info(f"Starting Indeed scrape: keywords='{request.keywords}', location='{request.location}', max_results={request.max_results}")

        try:
            # è°ƒç”¨ JobSpy æŠ“å–æ•°æ®
            df = scrape_jobs(
                site_name=['indeed'],
                search_term=request.keywords,
                location=request.location,
                results_wanted=request.max_results,
                country_indeed=settings.indeed_country,
                hours_old=None,  # ä¸é™åˆ¶å‘å¸ƒæ—¶é—´
            )

            logger.info(f"JobSpy returned {len(df)} results")

            # è½¬æ¢æ•°æ®
            jobs = []
            for idx, row in df.iterrows():
                try:
                    job = self._transform_job(row)
                    jobs.append(job)
                except Exception as e:
                    logger.warning(f"Failed to transform job at index {idx}: {e}")
                    continue

            # ğŸ”§ FIX: å»é‡ - åŸºäº source_id
            original_count = len(jobs)
            jobs = self._deduplicate_by_source_id(jobs)
            duplicates_removed = original_count - len(jobs)

            if duplicates_removed > 0:
                logger.warning(f"ç§»é™¤äº† {duplicates_removed} ä¸ªé‡å¤èŒä½ï¼ˆåŸºäº source_idï¼‰")

            # ğŸ“ NOTE: Indeed API æœç´¢è´¨é‡é—®é¢˜
            # Indeed çš„æœç´¢ç®—æ³•å¯èƒ½è¿”å›è¯­ä¹‰ç›¸å…³ä½†éç›®æ ‡ trade çš„èŒä½
            # ä¾‹å¦‚ï¼šæœç´¢ "carpenter" å¯èƒ½è¿”å› "Property Valuer"ï¼ˆæˆ¿äº§ä¼°ä»·å¸ˆï¼‰
            # è¿™äº›èŒä½çš„ trade å­—æ®µä¼šæ˜¯ None
            #
            # V1 MVP: ä¿æŒç°çŠ¶ï¼Œç”¨æˆ·å¯ä»¥é€šè¿‡ trade IS NOT NULL è¿‡æ»¤
            # V1.5 ä¼˜åŒ–é€‰é¡¹ï¼š
            #   1. åœ¨æ­¤å¤„æ·»åŠ åå¤„ç†è¿‡æ»¤ï¼Œä¸¢å¼ƒ trade=None çš„èŒä½
            #   2. ä½¿ç”¨æ›´ç²¾ç¡®çš„ Indeed API å‚æ•°ï¼ˆå¦‚æœæ”¯æŒï¼‰
            #   3. æ·»åŠ åŸºäºèŒä½æè¿°çš„äºŒæ¬¡éªŒè¯
            #
            # ç›¸å…³ä»£ç ä½ç½®ï¼š
            #   - Trade æå–é€»è¾‘: app/utils/trade_extractor.py
            #   - å‰ç«¯è¿‡æ»¤: (å¾…å®ç°) WHERE trade IS NOT NULL

            logger.info(f"Successfully transformed {len(jobs)} jobs (after deduplication)")
            return jobs

        except Exception as e:
            logger.error(f"Indeed scraping failed: {e}")
            raise ScraperException(f"Failed to scrape Indeed: {str(e)}")

    def _transform_job(self, row) -> JobPostingDTO:
        """
        å°† JobSpy è¿”å›çš„ DataFrame è¡Œè½¬æ¢ä¸º JobPostingDTO

        Args:
            row: DataFrame çš„ä¸€è¡Œæ•°æ®

        Returns:
            JobPostingDTO: æ ‡å‡†åŒ–çš„èŒä½æ•°æ®
        """
        # è§£æåœ°ç‚¹
        location_str = row.get('location', '')
        state, suburb = parse_location(location_str) if location_str else (None, None)

        # æå– trade
        title = row.get('title', '')
        trade = extract_trade(title) if title else None

        # æ ‡å‡†åŒ–å·¥ä½œç±»å‹
        job_type = row.get('job_type')
        employment_type = normalize_employment_type(job_type) if job_type else None

        # æå–è–ªèµ„èŒƒå›´
        min_amount = row.get('min_amount')
        max_amount = row.get('max_amount')

        # ç¡®ä¿è–ªèµ„ä¸º float æˆ– None
        pay_range_min = float(min_amount) if min_amount is not None and str(min_amount).replace('.', '').isdigit() else None
        pay_range_max = float(max_amount) if max_amount is not None and str(max_amount).replace('.', '').isdigit() else None

        # å¤„ç†å‘å¸ƒæ—¶é—´
        # ğŸ”§ FIX: ç¡®ä¿è¿”å› UTC timezone-aware datetimeï¼Œé¿å… PostgreSQL "Kind=Unspecified" é”™è¯¯
        date_posted = row.get('date_posted')
        posted_at = None
        if date_posted is not None:
            try:
                if isinstance(date_posted, str):
                    # è§£æ ISO æ ¼å¼æ—¶é—´å­—ç¬¦ä¸²å¹¶è½¬æ¢ä¸º UTC
                    dt = datetime.fromisoformat(date_posted.replace('Z', '+00:00'))
                    # ç¡®ä¿æ˜¯ timezone-aware ä¸”ä¸º UTC
                    if dt.tzinfo is None:
                        posted_at = dt.replace(tzinfo=timezone.utc)
                    else:
                        posted_at = dt.astimezone(timezone.utc)
                else:
                    # ç¡®ä¿å·²æœ‰çš„ datetime ä¹Ÿæ˜¯ timezone-aware UTC
                    if date_posted.tzinfo is None:
                        posted_at = date_posted.replace(tzinfo=timezone.utc)
                    else:
                        posted_at = date_posted.astimezone(timezone.utc)
            except Exception as e:
                logger.debug(f"Failed to parse date_posted: {e}")

        # ç”Ÿæˆ source_id
        job_id = row.get('id')
        if not job_id:
            job_id = self._generate_id({
                'title': title,
                'company': row.get('company', ''),
                'location': location_str
            })

        # æ„å»º JobPostingDTO
        job = JobPostingDTO(
            source=PlatformEnum.INDEED,
            source_id=str(job_id),
            title=title or 'Unknown',
            company=row.get('company', 'Unknown'),
            location_state=state,
            location_suburb=suburb,
            trade=trade,
            employment_type=employment_type,
            pay_range_min=pay_range_min,
            pay_range_max=pay_range_max,
            description=row.get('description'),
            requirements=None,  # Indeed ä¸å•ç‹¬æä¾› requirements
            tags=[],  # Indeed ä¸æä¾› tags
            posted_at=posted_at,
            scraped_at=datetime.utcnow(),
            job_url=row.get('job_url'),
            is_remote=row.get('is_remote'),
            company_url=row.get('company_url')
        )

        return job
