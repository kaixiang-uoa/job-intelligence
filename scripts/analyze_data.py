#!/usr/bin/env python3
"""
MVP æ•°æ®åˆ†æè„šæœ¬

ç”¨é€”ï¼š
1. è¿æ¥æ•°æ®åº“è·å–ç»Ÿè®¡æ•°æ®
2. ç”Ÿæˆå¯è§†åŒ–æŠ¥å‘Šï¼ˆæ–‡æœ¬æ ¼å¼ï¼‰
3. å¯¼å‡ºæ•°æ®åˆ° JSON/CSV

ä½¿ç”¨ï¼š
    python3 analyze_data.py
    python3 analyze_data.py --export json
    python3 analyze_data.py --export csv
"""

import psycopg2
import json
import csv
from datetime import datetime
from collections import defaultdict
import argparse


# æ•°æ®åº“é…ç½®
DB_CONFIG = {
    "host": "localhost",
    "port": 5432,
    "database": "jobintel",
    "user": "admin",
    "password": "dev123"
}


def get_db_connection():
    """è·å–æ•°æ®åº“è¿æ¥"""
    return psycopg2.connect(**DB_CONFIG)


def get_basic_stats(conn):
    """è·å–åŸºç¡€ç»Ÿè®¡æ•°æ®"""
    cur = conn.cursor()

    stats = {}

    # æ€»èŒä½æ•°
    cur.execute("SELECT COUNT(*) FROM job_postings")
    stats['total_jobs'] = cur.fetchone()[0]

    # æ´»è·ƒèŒä½æ•°
    cur.execute("SELECT COUNT(*) FROM job_postings WHERE is_active = true")
    stats['active_jobs'] = cur.fetchone()[0]

    # æŒ‰æ¥æºç»Ÿè®¡
    cur.execute("""
        SELECT source, COUNT(*)
        FROM job_postings
        GROUP BY source
    """)
    stats['by_source'] = dict(cur.fetchall())

    # æŒ‰ trade ç»Ÿè®¡
    cur.execute("""
        SELECT
            COALESCE(trade, 'NULL') as trade,
            COUNT(*)
        FROM job_postings
        GROUP BY trade
        ORDER BY COUNT(*) DESC
    """)
    stats['by_trade'] = dict(cur.fetchall())

    # æŒ‰å·ç»Ÿè®¡
    cur.execute("""
        SELECT
            COALESCE(location_state, 'NULL') as state,
            COUNT(*)
        FROM job_postings
        GROUP BY location_state
        ORDER BY COUNT(*) DESC
    """)
    stats['by_state'] = dict(cur.fetchall())

    cur.close()
    return stats


def check_data_quality(conn):
    """æ£€æŸ¥æ•°æ®è´¨é‡"""
    cur = conn.cursor()

    quality = {}

    # å»é‡æ£€æŸ¥
    cur.execute("""
        SELECT COUNT(*) FROM (
            SELECT source_id, COUNT(*)
            FROM job_postings
            GROUP BY source_id
            HAVING COUNT(*) > 1
        ) duplicates
    """)
    quality['duplicate_count'] = cur.fetchone()[0]

    # Trade æå–æˆåŠŸç‡
    cur.execute("""
        SELECT
            COUNT(*) as total,
            COUNT(trade) as with_trade
        FROM job_postings
    """)
    row = cur.fetchone()
    quality['trade_extraction_rate'] = round(100.0 * row[1] / row[0], 2) if row[0] > 0 else 0

    # Location æå–æˆåŠŸç‡
    cur.execute("""
        SELECT
            COUNT(*) as total,
            COUNT(location_state) as with_location
        FROM job_postings
    """)
    row = cur.fetchone()
    quality['location_extraction_rate'] = round(100.0 * row[1] / row[0], 2) if row[0] > 0 else 0

    # è–ªèµ„æ•°æ®å®Œæ•´æ€§
    cur.execute("""
        SELECT
            COUNT(*) as total,
            COUNT(pay_range_min) as with_salary
        FROM job_postings
    """)
    row = cur.fetchone()
    quality['salary_data_rate'] = round(100.0 * row[1] / row[0], 2) if row[0] > 0 else 0

    # è®¡ç®—æ•´ä½“è´¨é‡è¯„åˆ†
    dedup_score = 100 if quality['duplicate_count'] == 0 else 80
    quality['overall_score'] = round(
        (dedup_score + quality['trade_extraction_rate'] + quality['location_extraction_rate']) / 3,
        2
    )

    cur.close()
    return quality


def get_recent_jobs(conn, limit=10):
    """è·å–æœ€è¿‘çš„èŒä½"""
    cur = conn.cursor()

    cur.execute("""
        SELECT
            id,
            title,
            company,
            location_state,
            location_suburb,
            trade,
            employment_type,
            pay_range_min,
            pay_range_max,
            posted_at,
            source
        FROM job_postings
        ORDER BY posted_at DESC
        LIMIT %s
    """, (limit,))

    columns = [desc[0] for desc in cur.description]
    jobs = []
    for row in cur.fetchall():
        job = dict(zip(columns, row))
        # è½¬æ¢æ—¥æœŸä¸ºå­—ç¬¦ä¸²
        if job['posted_at']:
            job['posted_at'] = job['posted_at'].isoformat()
        jobs.append(job)

    cur.close()
    return jobs


def print_report(stats, quality, recent_jobs):
    """æ‰“å°æ–‡æœ¬æŠ¥å‘Š"""
    print("=" * 60)
    print("ğŸ“Š Job Intelligence MVP - æ•°æ®åˆ†ææŠ¥å‘Š")
    print("=" * 60)
    print(f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print()

    # åŸºç¡€ç»Ÿè®¡
    print("1ï¸âƒ£ åŸºç¡€ç»Ÿè®¡")
    print("-" * 60)
    print(f"æ€»èŒä½æ•°: {stats['total_jobs']}")
    print(f"æ´»è·ƒèŒä½æ•°: {stats['active_jobs']}")
    print()

    # æŒ‰æ¥æºåˆ†å¸ƒ
    print("2ï¸âƒ£ æ•°æ®æ¥æºåˆ†å¸ƒ")
    print("-" * 60)
    for source, count in stats['by_source'].items():
        percentage = round(100.0 * count / stats['total_jobs'], 2)
        print(f"{source:10s}: {count:5d} ({percentage:5.2f}%)")
    print()

    # æŒ‰ Trade åˆ†å¸ƒï¼ˆTop 10ï¼‰
    print("3ï¸âƒ£ Trade åˆ†å¸ƒï¼ˆTop 10ï¼‰")
    print("-" * 60)
    for i, (trade, count) in enumerate(list(stats['by_trade'].items())[:10], 1):
        print(f"{i:2d}. {trade:20s}: {count:4d}")
    print()

    # æŒ‰å·åˆ†å¸ƒ
    print("4ï¸âƒ£ åœ°ç‚¹åˆ†å¸ƒï¼ˆæŒ‰å·ï¼‰")
    print("-" * 60)
    for state, count in stats['by_state'].items():
        percentage = round(100.0 * count / stats['total_jobs'], 2)
        print(f"{state:5s}: {count:5d} ({percentage:5.2f}%)")
    print()

    # æ•°æ®è´¨é‡
    print("5ï¸âƒ£ æ•°æ®è´¨é‡è¯„ä¼°")
    print("-" * 60)
    print(f"é‡å¤æ•°æ®: {quality['duplicate_count']} ä¸ª")
    print(f"Trade æå–æˆåŠŸç‡: {quality['trade_extraction_rate']}%")
    print(f"åœ°ç‚¹æå–æˆåŠŸç‡: {quality['location_extraction_rate']}%")
    print(f"è–ªèµ„æ•°æ®å®Œæ•´æ€§: {quality['salary_data_rate']}%")
    print()
    print(f"æ•´ä½“è´¨é‡è¯„åˆ†: {quality['overall_score']}/100")

    if quality['overall_score'] >= 95:
        print("âœ… ä¼˜ç§€ï¼æ•°æ®è´¨é‡è¾¾åˆ°ç”Ÿäº§æ ‡å‡†")
    elif quality['overall_score'] >= 80:
        print("âš ï¸  è‰¯å¥½ï¼Œä½†ä»æœ‰ä¼˜åŒ–ç©ºé—´")
    else:
        print("âŒ æ•°æ®è´¨é‡éœ€è¦æ”¹è¿›")
    print()

    # æœ€è¿‘èŒä½é¢„è§ˆ
    print("6ï¸âƒ£ æœ€è¿‘èŒä½é¢„è§ˆï¼ˆæœ€æ–° 10 æ¡ï¼‰")
    print("-" * 60)
    for i, job in enumerate(recent_jobs, 1):
        title = job['title'][:40] + '...' if len(job['title']) > 40 else job['title']
        print(f"{i:2d}. {title}")
        print(f"    å…¬å¸: {job['company'] or 'N/A'} | å·: {job['location_state'] or 'N/A'} | Trade: {job['trade'] or 'N/A'}")
    print()

    print("=" * 60)
    print("âœ… åˆ†æå®Œæˆ")
    print("=" * 60)


def export_to_json(stats, quality, recent_jobs, filename="data_analysis.json"):
    """å¯¼å‡ºä¸º JSON"""
    data = {
        "generated_at": datetime.now().isoformat(),
        "statistics": stats,
        "quality": quality,
        "recent_jobs": recent_jobs
    }

    with open(filename, 'w', encoding='utf-8') as f:
        json.dump(data, f, indent=2, ensure_ascii=False)

    print(f"âœ… æ•°æ®å·²å¯¼å‡ºåˆ°: {filename}")


def export_to_csv(recent_jobs, filename="recent_jobs.csv"):
    """å¯¼å‡ºä¸º CSV"""
    if not recent_jobs:
        print("âš ï¸  æ²¡æœ‰æ•°æ®å¯å¯¼å‡º")
        return

    with open(filename, 'w', newline='', encoding='utf-8') as f:
        writer = csv.DictWriter(f, fieldnames=recent_jobs[0].keys())
        writer.writeheader()
        writer.writerows(recent_jobs)

    print(f"âœ… èŒä½æ•°æ®å·²å¯¼å‡ºåˆ°: {filename}")


def main():
    parser = argparse.ArgumentParser(description='MVP æ•°æ®åˆ†æè„šæœ¬')
    parser.add_argument('--export', choices=['json', 'csv', 'both'],
                        help='å¯¼å‡ºæ ¼å¼ (json/csv/both)')
    args = parser.parse_args()

    try:
        # è¿æ¥æ•°æ®åº“
        conn = get_db_connection()

        # è·å–æ•°æ®
        stats = get_basic_stats(conn)
        quality = check_data_quality(conn)
        recent_jobs = get_recent_jobs(conn, limit=10)

        # æ‰“å°æŠ¥å‘Š
        print_report(stats, quality, recent_jobs)

        # å¯¼å‡ºæ•°æ®
        if args.export in ['json', 'both']:
            export_to_json(stats, quality, recent_jobs)

        if args.export in ['csv', 'both']:
            export_to_csv(recent_jobs)

        conn.close()

    except psycopg2.Error as e:
        print(f"âŒ æ•°æ®åº“é”™è¯¯: {e}")
    except Exception as e:
        print(f"âŒ é”™è¯¯: {e}")


if __name__ == "__main__":
    main()
